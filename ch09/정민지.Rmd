---
title: "model"
author: "jeong minji"
date: '2021 5 3 '
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rpart)
library(caret)
library(randomForest)
library(e1071)
library(class)
```

## 연습문제01
### ucla 데이터
```{r}
# 데이터 불러오기
ucla <- read.csv('https://stats.idre.ucla.edu/stat/data/binary.csv')
ucla$admit <- factor(ucla$admit)
#as.factor(ucla$admit) -> 값이 바뀌진 않음

set.seed(2021)
train_index <- createDataPartition(ucla$admit, p=0.8,list = F) 
ucla_train <- ucla[train_index,]
ucla_test <- ucla[-train_index,]

# 결정트리
dtc <- rpart(admit~.,ucla_train) 
pred <- predict(dtc, ucla_test, type='class')
table(pred,ucla_test$admit) # 여기서 [1,1],[2,2]출력
t <- table(pred,ucla_test$admit)
dt_a <- (t[1,1] + t[2,2]) / nrow(ucla_test) #정확도 확인
dt_a
#confusionMatrix(pred,ucla_test$admit) #혼동행렬, 혼돈행렬, 오차행렬
#rpart.plot(dtc)

# 랜덤포레스트
rf <- randomForest(admit ~.,ucla_train)
pred <- predict(rf, ucla_test, type = 'class')
t <- table(pred,ucla_test$admit)
rf_a <- (t[1,1] + t[2,2]) / nrow(ucla_test)
rf_a
#confusionMatrix(pred, ucla_test$admit)
#plot(rf)

# SVM
svc <- svm(admit~.,ucla_train)
pred <- predict(svc, ucla_test, type='class')
t <- table(pred, ucla_test$admit) 
sv_a <- (t[1,1] + t[2,2]) / nrow(ucla_test)
sv_a
#confusionMatrix(pred, ucla_test$admit)

# K-NN / 학습자체가 예측임
k <- knn(ucla_train[,2:4],ucla_test[,2:4],ucla_train$admit,k=5)
t <- table(pred, ucla_test$admit) 
kn_a <- (t[1,1] + t[2,2]) / nrow(ucla_test)
kn_a
#confusionMatrix(k,ucla_test$admit)

# 로지스틱 회귀(이진분류일 경우)
lr <- glm(admit~.,ucla_train,family = binomial)
lr_pred <- predict(lr, ucla_test, type = 'response')
lr_pred
lf_pred <- ifelse(lr_pred > 0.5,1,0)
t <- table(lr_pred,ucla_test$admit)
lr_a <- (t[1,1]+t[2,2]) / nrow(ucla_test)
lr_a

print(paste(dt_a, rf_a,sv_a,kn_a,lr_a))
```

## 연습문제02
### wine 데이터
```{r}
setwd('C:/workspace/R')
wine <- read.table('data/wine.data.txt', sep = ',')
columns <- readLines('data/wine.name.txt')
names(wine)[2:14] <- substr(columns, 4, nchar(columns))
names(wine)[1] <- 'Y'
head(wine)
str(wine)
wine$Y <- factor(wine$Y)

# 훈련/테스트 데이터셋 만들기
set.seed(2021)
train_index <- createDataPartition(wine$Y, p=0.8, list=F)
wine_train <- wine[train_index,]
wine_test <- wine[-train_index,]
table(wine$Y)
table(wine_train$Y)

# 결정 트리
dt <- rpart(Y~., wine_train)
dt_pred <- predict(dt, wine_test, type='class')
t <- table(dt_pred, wine_test$Y)
dt_acc <- (t[1,1] + t[2,2] + t[3,3]) / nrow(wine_test)
dt_acc

# 랜덤 포레스트
rf <- randomForest(Y~., wine_train)
rf_pred <- predict(rf, wine_test, type='class')
t <- table(rf_pred, wine_test$Y)
rf_acc <- (t[1,1] + t[2,2] + t[3,3]) / nrow(wine_test)
rf_acc

# 서포트 벡터 머신
sv <- svm(Y~., wine_train)
sv_pred <- predict(sv, wine_test, type='class')
t <- table(sv_pred, wine_test$Y)
sv_acc <- (t[1,1] + t[2,2] + t[3,3]) / nrow(wine_test)
sv_acc

# K-NN
kn_pred <- knn(wine_train[, 2:14], wine_test[, 2:14], 
               wine_train$Y, k=5)
t <- table(kn_pred, wine_test$Y)
kn_acc <- (t[1,1] + t[2,2] + t[3,3]) / nrow(wine_test)
kn_acc

print(paste(dt_acc, rf_acc, sv_acc, kn_acc))
```

